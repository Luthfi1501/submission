{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Proyek Analisis Data: Brazilian E-Commerce Public Dataset by Olist\n",
        "- **Nama:** Luthfi Mohamad Latief\n",
        "- **Email:** luthfimo1501@gmail.com\n",
        "- **ID Dicoding:** luthfi_m_latief"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puroXMUf3K_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0raob58DC0"
      },
      "source": [
        "## Menentukan Pertanyaan Bisnis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQeQ5YF8DC0"
      },
      "source": [
        "- Mengidentifikasi seberapa sering seorang pelanggan melakukan transaksi (frequency)\n",
        "- Mengidentifikasi seberapa besar revenue berdasarkan kategori product (monetery)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PC7Hr-5ltPDC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVYwaObI8DC1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sh51Xy8DC1"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXU2GBYu8DC1"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zjCBk1BI8DC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "6a682eb1-ff2b-4b17-8212-79e6be1619ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/olist_customers_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-88e4b8d6bd43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#gathering process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustomers_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/olist_customers_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#memanggil file csv customers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcustomers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#mengeluarkan list data pada table customers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgeolocation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/olist_geolocation_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#memanggil file csv geolocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/olist_customers_dataset.csv'"
          ]
        }
      ],
      "source": [
        "#gathering process\n",
        "customers_df = pd.read_csv(\"data/olist_customers_dataset.csv\")#memanggil file csv customers\n",
        "customers_df.head()#mengeluarkan list data pada table customers\n",
        "\n",
        "geolocation_df = pd.read_csv(\"data/olist_geolocation_dataset.csv\")#memanggil file csv geolocation\n",
        "geolocation_df.head()#mengeluarkan list data pada table geolocation\n",
        "\n",
        "order_items_df = pd.read_csv(\"data/olist_order_items_dataset.csv\")#memanggil file csv order_items\n",
        "order_items_df.head()#mengeluarkan list data pada table order_items\n",
        "\n",
        "order_payments_df = pd.read_csv(\"data/olist_order_payments_dataset.csv\")#memanggil file csv order_payments\n",
        "order_payments_df.head()#mengeluarkan list data pada table order_payments\n",
        "\n",
        "order_reviews_df = pd.read_csv(\"data/olist_order_reviews_dataset.csv\")#memanggil file csv order_reviews\n",
        "order_reviews_df.head()#mengeluarkan list data pada table order_reviews\n",
        "\n",
        "orders_df = pd.read_csv(\"data/olist_orders_dataset.csv\")#memanggil file csv orders\n",
        "orders_df.head()#mengeluarkan list data pada table orders\n",
        "\n",
        "products_df = pd.read_csv(\"data/olist_products_dataset.csv\")#memanggil file csv products\n",
        "products_df.head()#mengeluarkan list data pada table products\n",
        "\n",
        "sellers_df = pd.read_csv(\"data/olist_sellers_dataset.csv\")#memanggil file csv sellers\n",
        "sellers_df.head()#mengeluarkan list data pada table sellers\n",
        "\n",
        "product_category_name_translation_df = pd.read_csv(\"data/product_category_name_translation.csv\")#memanggil file csv product_category_name_translation\n",
        "product_category_name_translation_df.head()#mengeluarkan list data pada table product_category_name_translation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "- Menyiapkan semua table dari dataset\n",
        "- Menampilkan isi table (.csv) menggunakan pendekatan dataframe"
      ],
      "metadata": {
        "id": "MMi6xGaDkbCi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSiqaZp8DC1"
      },
      "source": [
        "### Assessing Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assessing process\n",
        "customers_df.info()#cek kondisi struktur data atas table customers\n",
        "customers_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table customers, terlihat semua kolom tidak ada data kosong\n",
        "print(\"Jumlah duplikasi table customers: \", customers_df.duplicated().sum())#cek jumlah duplikasi data pada table customers, terlihat tidak ada data yang duplikasi\n",
        "customers_df.describe()#cek ringkasan parameter statistik table customers, terlihat tidak ada keanehan pada parameter statistik table customers\n",
        "\n",
        "geolocation_df.info()#cek kondisi struktur data atas table geolocation\n",
        "geolocation_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table geolocation, terlihat semua kolom tidak ada data kosong\n",
        "print(\"Jumlah duplikasi table geolocation: \", geolocation_df.duplicated().sum())#cek jumlah duplikasi data pada table geolocation, terlihat 261831 data yang duplikasi\n",
        "geolocation_df.describe()#cek ringkasan parameter statistik table geolocation, terlihat tidak ada keanehan pada parameter statistik table geolocation\n",
        "\n",
        "order_items_df.info()#cek kondisi struktur data atas table order_items\n",
        "order_items_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table order_items, terlihat semua kolom tidak ada data kosong\n",
        "print(\"Jumlah duplikasi table order_items: \", order_items_df.duplicated().sum())#cek jumlah duplikasi data pada table order_items, terlihat tidak ada data yang duplikasi\n",
        "order_items_df.describe()#cek ringkasan parameter statistik table order_items, terlihat kolom shipping_limit_date bertipe object seharusnya datetime\n",
        "\n",
        "order_payments_df.info()#cek kondisi struktur data atas table order_payments\n",
        "order_payments_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table order_payments, terlihat semua kolom tidak ada data kosong\n",
        "print(\"Jumlah duplikasi table order_payments: \", order_payments_df.duplicated().sum())#cek jumlah duplikasi data pada table order_payments, terlihat tidak ada data yang duplikasi\n",
        "order_payments_df.describe()#cek ringkasan parameter statistik table order_payments, terlihat tidak ada keanehan pada parameter statistik table order_payments\n",
        "\n",
        "order_reviews_df.info()#cek kondisi struktur data atas table order_reviews\n",
        "order_reviews_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table order_reviews, terlihat kolom review_comment_title dan review_comment_message terdapat data kosong\n",
        "print(\"Jumlah duplikasi table order_reviews: \", order_reviews_df.duplicated().sum())#cek jumlah duplikasi data pada table order_reviews, terlihat tidak ada data yang duplikasi\n",
        "order_reviews_df.describe()#cek ringkasan parameter statistik table order_reviews, terlihat kolom review_creation_date bertipe object seharusnya datetime\n",
        "\n",
        "orders_df.info()#cek kondisi struktur data atas table orders\n",
        "orders_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table orders, terlihat kolom order_approve_at, order_delivered_carrier_date, order_delivered_customer_date  terdapat data kosong\n",
        "print(\"Jumlah duplikasi table orders: \", orders_df.duplicated().sum())#cek jumlah duplikasi data pada table orders, terlihat tidak ada data yang duplikasi\n",
        "orders_df.describe()#cek ringkasan parameter statistik table orders, terlihat kolom order_delivered_carrier_date, order_delivered_customer_date dan order_estimated_delivery_date bertipe object seharusnya datetime\n",
        "\n",
        "products_df.info()#cek kondisi struktur data atas table products\n",
        "products_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table products, terlihat kolom product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_wight_g, product_length_cm, product_height_cm, product_width_cm  terdapat data kosong\n",
        "print(\"Jumlah duplikasi table products: \", products_df.duplicated().sum())#cek jumlah duplikasi data pada table orders, terlihat tidak ada data yang duplikasi\n",
        "products_df.describe()#cek ringkasan parameter statistik table products,  tidak ada keanehan pada parameter statistik\n",
        "\n",
        "sellers_df.info()#cek kondisi struktur data atas table sellers\n",
        "sellers_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table sellers, terlihat kolom tidak terdapat data kosong\n",
        "print(\"Jumlah duplikasi table sellers: \", sellers_df.duplicated().sum())#cek jumlah duplikasi data pada table sellers, terlihat tidak ada data yang duplikasi\n",
        "sellers_df.describe()#cek ringkasan parameter statistik table sellers, tidak ada keanehan pada parameter statistik\n",
        "\n",
        "product_category_name_translation_df.info()#cek kondisi struktur data atas table product_category_name_translation\n",
        "product_category_name_translation_df.isna().sum()#cek jumlah data kosong pada tiap kolom di table product_category_name_translation tidak terdapat data kosong\n",
        "print(\"Jumlah duplikasi table sellers: \", product_category_name_translation_df.duplicated().sum())#cek jumlah duplikasi data pada table product_category_name_translation, terlihat tidak ada data yang duplikasi\n",
        "product_category_name_translation_df.describe()#cek ringkasan parameter statistik table product_category_name_translation, tidak ada keanehan pada parameter statistik\n"
      ],
      "metadata": {
        "id": "ax-3tEjc9Cj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ],
      "metadata": {
        "id": "7dtxhAPrkhPL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhN5R4hr8DC1"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleansing process\n",
        "\n",
        "#table geolocation\n",
        "#1. case nya memiliki beberapa data duplikasi\n",
        "geolocation_df.drop_duplicates(inplace=True)#menghapus data yang terindikasi duplikasi\n",
        "print(\"Jumlah duplikasi table geolocation: \", geolocation_df.duplicated().sum())#terlihat jumlah data yang terduplikasi bernilai 0\n",
        "\n",
        "#table order_item\n",
        "#1. case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "datetime_columns = [\"shipping_limit_date\"]#inisiasi kolom yang ingin dirubah tipe datanya\n",
        "for column in datetime_columns:\n",
        "  order_items_df[column] = pd.to_datetime(order_items_df[column])#mencari dan mengkonversi tipe data object pada kolom shipping_limit_date datetime pada table order_items\n",
        "order_items_df.info()#cek ulang struktur data table order_items\n",
        "\n",
        "#table order_reviews\n",
        "#1. case nya memiliki beberapa data duplikasi\n",
        "#2. case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "order_reviews_df.drop_duplicates(inplace=True)#menghapus data yang terindikasi duplikasi\n",
        "print(\"Jumlah duplikasi table order_reviews: \", order_reviews_df.duplicated().sum())#terlihat jumlah data yang terduplikasi bernilai 0\n",
        "datetime_columns = [\"review_creation_date\"]#inisiasi kolom yang ingin dirubah tipe datanya\n",
        "for column in datetime_columns:\n",
        "  order_reviews_df[column] = pd.to_datetime(order_reviews_df[column])#mencari dan mengkonversi tipe data object pada kolom review_creation_date datetime pada table order_items\n",
        "order_reviews_df.info()#cek ulang struktur data table order_reviews\n",
        "\n",
        "#table orders\n",
        "#1. case nya memiliki beberapa data duplikasi\n",
        "#2. case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "orders_df.drop_duplicates(inplace=True)#menghapus data yang terindikasi duplikasi\n",
        "print(\"Jumlah duplikasi table orders: \", orders_df.duplicated().sum())#terlihat jumlah data yang terduplikasi bernilai 0\n",
        "datetime_columns = [\"order_delivered_carrier_date\",\"order_delivered_customer_date\",\"order_estimated_delivery_date\"]#inisiasi kolom yang ingin dirubah tipe datanya\n",
        "for column in datetime_columns:\n",
        "  orders_df[column] = pd.to_datetime(orders_df[column])#mencari dan mengkonversi tipe data object pada kolom review_creation_date datetime pada table orders\n",
        "orders_df.info()#cek ulang struktur data table order_reviews\n",
        "\n",
        "#table products\n",
        "#1. case nya memiliki beberapa data kosong di beberapa kolom\n",
        "#1.1 jika tipe data kolom adalah object maka akan diganti dengan kata tertentu\n",
        "#1.2 jika tipe data kolom adalah integer/float maka akan diganti dengan nilai mean (rata-rata)\n",
        "products_df[products_df.product_category_name.isna()]#cek data dengan kolom product_category_name bernilai kosong/null/NaN pada table products\n",
        "products_df[\"product_category_name\"] = products_df[\"product_category_name\"].fillna(\"Belum Ditentukan\")#mengganti nilai kosong dengan 'Belum Ditentukan'\n",
        "mean_values = products_df[[\"product_name_lenght\", \"product_description_lenght\", \"product_photos_qty\", \"product_weight_g\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"]].mean()\n",
        "products_df[[\"product_name_lenght\", \"product_description_lenght\", \"product_photos_qty\", \"product_weight_g\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"]] = products_df[[\"product_name_lenght\", \"product_description_lenght\", \"product_photos_qty\", \"product_weight_g\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\"]].fillna(mean_values)\n",
        "products_df.isna().sum()#cek data dengan kolom bernilai kosong/null/NaN pada table products\n"
      ],
      "metadata": {
        "id": "jVnYpprE9Evz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "1. Table Geolocation\n",
        "- Case nya memiliki beberapa data duplikasi\n",
        "\n",
        "2. Table Order Item\n",
        "- Case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "\n",
        "3. Table Order Reviews\n",
        "- Case nya memiliki beberapa data duplikasi\n",
        "- Case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "\n",
        "4. Table Orders\n",
        "- Case nya memiliki beberapa data duplikasi\n",
        "- Case nya memiliki kolom yang bertipe data tidak sesuai yang seharusnya\n",
        "\n",
        "5. Table Products\n",
        "- Case nya memiliki beberapa data kosong di beberapa kolom\n",
        "- Jika tipe data kolom adalah object maka akan diganti dengan kata\n",
        "- Jika tipe data kolom adalah integer/float maka akan diganti dengan nilai mean (rata-rata)"
      ],
      "metadata": {
        "id": "Q_5ejIqckiSP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-Y6wU38DC1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW7WF2kr8DC1"
      },
      "source": [
        "### Explore ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9CQCZjk8DC2"
      },
      "outputs": [],
      "source": [
        "#join table orders dengan customers\n",
        "orders_customers_df = pd.merge(\n",
        "    left=orders_df,\n",
        "    right=customers_df,\n",
        "    how=\"left\", #menerapkan left join tbale orders dengan table customers\n",
        "    left_on=\"customer_id\",\n",
        "    right_on=\"customer_id\"\n",
        ")\n",
        "orders_customers_df.head()\n",
        "\n",
        "#menampilkan pivot order terbanyak berdasarkan kota sebanyak 10 data\n",
        "orders_customers_df.groupby(by=\"customer_city\").order_id.nunique().sort_values(ascending=False).reset_index().head(10)\n",
        "\n",
        "#join data table order_items dan order_payments\n",
        "order_items_payments_df = pd.merge(\n",
        "    left=order_items_df,\n",
        "    right=order_payments_df,\n",
        "    how=\"left\",#menerapkan left join table order_items dengan order_payments\n",
        "    left_on=\"order_id\",\n",
        "    right_on=\"order_id\"\n",
        ")\n",
        "order_items_payments_df.head()\n",
        "\n",
        "#join data table order_items_payments dan products\n",
        "order_items_payments_products_df = pd.merge(\n",
        "    left=order_items_payments_df,\n",
        "    right=products_df,\n",
        "    how=\"left\",#menerapkan left join table order_items_payments dengan products\n",
        "    left_on=\"product_id\",\n",
        "    right_on=\"product_id\"\n",
        ")\n",
        "order_items_payments_products_df.head()\n",
        "\n",
        "#menampilkan urutan 10 revenue order terbanyak berdasarkan kategori product\n",
        "order_items_payments_products_df.groupby(by=\"product_category_name\").agg({\n",
        "    \"payment_value\": \"sum\",\n",
        "}).sort_values(by=\"payment_value\", ascending=False).reset_index().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "- Join table orders dengan table customers\n",
        "- Menampilkan urutan 10 order terbanyak berdasarkan kota (aliasing orders_customers)\n",
        "- Join data table order_items dengan order_payments (aliasing order_items_payments)\n",
        "- Join table order_items_payments dengan table product\n",
        "- Menampilkan urutan 10 revenue order terbanyak berdasarkan kategori product\n"
      ],
      "metadata": {
        "id": "th_Lzl2Fkj9O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsyZjqak8DC2"
      },
      "source": [
        "## Visualization & Explanatory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxOiQ6n8DC2"
      },
      "source": [
        "### Pertanyaan 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swJUdAD8DC2"
      },
      "outputs": [],
      "source": [
        "#Visualization & Explanatory\n",
        "#Mnampilkan 10 kota dengan order terbanyak\n",
        "orders_by_city_df = all_df.groupby('customer_city').agg({\n",
        "    \"order_id\": \"nunique\"\n",
        "}).reset_index()\n",
        "\n",
        "orders_by_city_df.rename(columns={\n",
        "    \"order_id\": \"order_count\",\n",
        "    \"customer_city\": \"city\"\n",
        "}, inplace=True)\n",
        "\n",
        "# Menghitung jumlah order per kota\n",
        "city_order_counts = all_df.groupby('customer_city')['order_id'].nunique().sort_values(ascending=False)\n",
        "\n",
        "# Menampilkan 10 kota dengan order terbanyak\n",
        "top_10_cities = city_order_counts.head(10)\n",
        "\n",
        "# Plotting untuk menampilkan 10 kota dengan order terbanyak\n",
        "plt.figure(figsize=(10, 5))\n",
        "top_10_cities.plot(kind='bar', color='#72BCD4')\n",
        "plt.title(\"10 Kota dengan Order Terbanyak (Ribu)\", loc=\"center\", fontsize=20)\n",
        "plt.xlabel(\"Kota\", fontsize=12)\n",
        "plt.ylabel(\"Jumlah Order (Ribu)\", fontsize=12)\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgHI7CiU8DC2"
      },
      "source": [
        "### Pertanyaan 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0lCsvO8DC2"
      },
      "outputs": [],
      "source": [
        "#Menampilkan 10 revenue order terbanyak berdasarkan kategori product\n",
        "revenue_by_category_df = all_df.groupby('product_category_name').agg({\n",
        "    \"payment_value\": \"sum\"  # Menghitung total payment_value untuk setiap kategori produk\n",
        "}).reset_index()\n",
        "\n",
        "revenue_by_category_df.rename(columns={\n",
        "    \"payment_value\": \"total_revenue\",\n",
        "    \"product_category_name\": \"category\"\n",
        "}, inplace=True)\n",
        "\n",
        "# Mengurutkan kategori produk berdasarkan total revenue terbanyak\n",
        "revenue_by_category_df = revenue_by_category_df.sort_values(by='total_revenue', ascending=False)\n",
        "\n",
        "# Menampilkan 10 kategori produk dengan revenue terbanyak\n",
        "top_10_revenue_categories = revenue_by_category_df.head(10)\n",
        "\n",
        "# Plotting untuk menampilkan 10 kategori produk dengan revenue terbanyak\n",
        "plt.figure(figsize=(10, 5))\n",
        "top_10_revenue_categories.plot(kind='barh', x='category', y='total_revenue', color='#72BCD4', legend=False)\n",
        "plt.title(\"10 Kategori Produk dengan Revenue Terbanyak (Juta)\", loc=\"center\", fontsize=20)\n",
        "plt.xlabel(\"Total Revenue (Juta)\", fontsize=12)\n",
        "plt.ylabel(\"Kategori Produk\", fontsize=12)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "- Visualisasi pertama, menampilkan 10 kota dengan jumlah order terbanyak dengan diagram batang secara vertikal\n",
        "- Visualisasi kedua, menampilkan 10 kategori product dengan jumlah revenue terbesar dengan diagram batang secara horizontal"
      ],
      "metadata": {
        "id": "_0-36BDLklRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis Lanjutan (Opsional)"
      ],
      "metadata": {
        "id": "9y4VUsmcYNZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWhnzsJGYUCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WeHlCeX8DC2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTcyR48Y8DC2"
      },
      "source": [
        "- Bahwa kota dengan order terbanyak adalah Sao Paulo dengan jumlah order lebih dari 14.000 order\n",
        "- Bahwa kategori product dengan revenue terbesar adalah Cama Mesa Banho dengan revenue lebih dari 1.600.000"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:21:23) [MSC v.1916 32 bit (Intel)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}